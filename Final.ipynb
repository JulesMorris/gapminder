{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "018a75bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from imports import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0caa0dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, LassoLars, TweedieRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "#from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from scipy import stats\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# specify decimal places to display\n",
    "pd.set_option('display.float_format', lambda x: '%.2f' % x)\n",
    "\n",
    "#import pursuit_of_happiness"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be0617ad",
   "metadata": {},
   "source": [
    "<h1 style = \"border:10px; border-style:groove; border-color:maroon; padding: 1em; text-align: center;\" >  Pursuit of Happyness <br> <img src= \"cali.webp\" width = \"700\" align = \"center\"> </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d11979a",
   "metadata": {},
   "source": [
    "# Project Planning\n",
    "\n",
    "- Acquire data from the Codeup Database and store the process as a function for replication. Save the function in a wrangle.py file to import into the Final Report Notebook.\n",
    "\n",
    "- View data to gain understanding of the dataset and to create the readme.\n",
    "    \n",
    "- Create README.md with data dictionary, project and business goals, documentation of the initial hypotheses.\n",
    "    \n",
    "- Clean and prepare data for the first iteration through the data pipeline. Store this as a function to automate the process, store the function in the wrangle.py module, and prepare data in Final Report Notebook by importing and using the funtion.\n",
    "\n",
    "- Clearly define at least two hypotheses, set an alpha, run the statistical tests needed, reject or fail to reject the Null Hypothesis, and document findings and takeaways.\n",
    "   \n",
    "- Establish a baseline accuracy and document well.\n",
    "\n",
    "- Train four different regression models.\n",
    "    \n",
    "- Evaluate models on train and validate datasets.\n",
    "    \n",
    "- Choose the model with that performs the best and evaluate that single model on the test dataset.    \n",
    "\n",
    "- Document executive summary, conclusions, takeaways, and next steps in the Final Report Notebook.\n",
    "\n",
    "- Upload README.md, Data Dictionary, wrangle.py, Project Scratch Notebook, Final Report Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14c7fdc2",
   "metadata": {},
   "source": [
    "<hr style=\"border-top: 10px groove lightsteelblue; margin-top: 1px; margin-bottom: 2px\"></hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ed55b22",
   "metadata": {},
   "source": [
    "# Executive Summary\n",
    "\n",
    "- The regression models had similar performance, with the GLM Model using Tweedie Regression resulting in the lowest overall Root Mean Squared Error.\n",
    "\n",
    "    - The features included in this model:\n",
    "    \n",
    "        - Area\n",
    "        - Age \n",
    "        - Bedrooms/Bathrooms\n",
    "   \n",
    "- Using clustering for feature engineering and feature development proved inconclusive. \n",
    "\n",
    "- The model outperformed the baseline accuracy.\n",
    "\n",
    "- Several insights and statistical testing during the exploratory data analysis revealed that analysis by absolute log error is beneficial for gaining insights into which counties and features produce the most log error volatility."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54aa7ac1",
   "metadata": {},
   "source": [
    "<h1 style=\"border-bottom: 10px groove lightsteelblue; margin-top: 1px; margin-bottom: 2px; text-align: left;\">\n",
    "Data Preparation </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e0789d",
   "metadata": {},
   "source": [
    "#### How it started:\n",
    "\n",
    "- The original dataframe was ~ 77,381 rows and 67 columns\n",
    "\n",
    "    - Redundant and unnecessary columns and columns missing entire rows were dropped.\n",
    "    - Outliers were handled using IQR.\n",
    "    - Features were added.\n",
    "    - Some nulls were imputed.\n",
    "    \n",
    "#### How it's going:\n",
    "\n",
    "- In the end, the dataframe before the train, test, and split is 39687 rows and 45 columns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "728ba237",
   "metadata": {},
   "source": [
    "<h1 style=\"border-bottom: 10px groove lightsteelblue; margin-top: 1px; margin-bottom: 2px; text-align: left;\">\n",
    "Data Aquisition </hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62745ebf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>happiness_rank</th>\n",
       "      <th>happiness_score</th>\n",
       "      <th>gdp_per_cap</th>\n",
       "      <th>social_support</th>\n",
       "      <th>healthy_life_exp</th>\n",
       "      <th>freedom</th>\n",
       "      <th>generosity</th>\n",
       "      <th>corruption_perception</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>806</th>\n",
       "      <td>Taiwan</td>\n",
       "      <td>25.00</td>\n",
       "      <td>6.46</td>\n",
       "      <td>10.78</td>\n",
       "      <td>0.89</td>\n",
       "      <td>69.60</td>\n",
       "      <td>0.77</td>\n",
       "      <td>-0.07</td>\n",
       "      <td>0.73</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>876</th>\n",
       "      <td>Turkmenistan</td>\n",
       "      <td>95.00</td>\n",
       "      <td>5.12</td>\n",
       "      <td>9.75</td>\n",
       "      <td>0.96</td>\n",
       "      <td>62.21</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.88</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>Uruguay</td>\n",
       "      <td>31.00</td>\n",
       "      <td>6.38</td>\n",
       "      <td>1.09</td>\n",
       "      <td>1.46</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.15</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1018</th>\n",
       "      <td>China</td>\n",
       "      <td>84.00</td>\n",
       "      <td>5.34</td>\n",
       "      <td>9.67</td>\n",
       "      <td>0.81</td>\n",
       "      <td>69.59</td>\n",
       "      <td>0.90</td>\n",
       "      <td>-0.15</td>\n",
       "      <td>0.76</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>Armenia</td>\n",
       "      <td>121.00</td>\n",
       "      <td>4.36</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           country  happiness_rank  happiness_score  gdp_per_cap  \\\n",
       "806         Taiwan           25.00             6.46        10.78   \n",
       "876   Turkmenistan           95.00             5.12         9.75   \n",
       "500        Uruguay           31.00             6.38         1.09   \n",
       "1018         China           84.00             5.34         9.67   \n",
       "278        Armenia          121.00             4.36         0.86   \n",
       "\n",
       "      social_support  healthy_life_exp  freedom  generosity  \\\n",
       "806             0.89             69.60     0.77       -0.07   \n",
       "876             0.96             62.21     0.83        0.19   \n",
       "500             1.46              0.77     0.62        0.13   \n",
       "1018            0.81             69.59     0.90       -0.15   \n",
       "278             0.62              0.64     0.14        0.08   \n",
       "\n",
       "      corruption_perception  year  \n",
       "806                    0.73  2020  \n",
       "876                    0.88  2020  \n",
       "500                    0.15  2018  \n",
       "1018                   0.76  2021  \n",
       "278                    0.04  2016  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('happy.csv')\n",
    "\n",
    "df = df.fillna(0)\n",
    "\n",
    "#train, test, split\n",
    "train_validate, test = train_test_split(df, test_size = .2, random_state = 123)\n",
    "train, validate = train_test_split(train_validate, test_size = .3, random_state = 123)\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f33b1d3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(606, 10)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6bc5c724",
   "metadata": {},
   "outputs": [],
   "source": [
    "uber_happy = train[['country', 'happiness_score']].groupby('country').mean().sort_values(by = 'happiness_score', ascending = False)\n",
    "uber_happy = uber_happy.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bd3e4f92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.682233315890301"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uber_happy.happiness_score.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bc53697d",
   "metadata": {},
   "outputs": [],
   "source": [
    "so_sad = train[['country', 'happiness_score']].groupby('country').mean().sort_values(by = 'happiness_score', ascending = False)\n",
    "so_sad = so_sad.tail(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b49429ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.72493342986263"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "so_sad.happiness_score.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f072c28d",
   "metadata": {},
   "source": [
    "<h1 style=\"border-bottom: 10px groove lightsteelblue; margin-top: 1px; margin-bottom: 2px; text-align: left;\">\n",
    "Exploratory Analysis/Statistical Testing <br></hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fcd620f",
   "metadata": {},
   "source": [
    "#### Initial Questions:\n",
    "\n",
    "   - What are some of the drivers of happiness? \n",
    "   - Are some factors more significant than others?\n",
    "   - Is it better to be rich in a poor country or poor in a rich country? - Hans Rosling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd5cdcd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1a2231d5",
   "metadata": {},
   "source": [
    "<hr style=\"border-top: 5px groove blanchedalmond; margin-top: 1px; margin-bottom: 1px\"></hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db2ac37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b3d5ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9e6fff50",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d505ad29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>happiness_rank</th>\n",
       "      <th>happiness_score</th>\n",
       "      <th>gdp_per_cap</th>\n",
       "      <th>social_support</th>\n",
       "      <th>healthy_life_exp</th>\n",
       "      <th>freedom</th>\n",
       "      <th>generosity</th>\n",
       "      <th>corruption_perception</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>606.00</td>\n",
       "      <td>606.00</td>\n",
       "      <td>606.00</td>\n",
       "      <td>606.00</td>\n",
       "      <td>606.00</td>\n",
       "      <td>606.00</td>\n",
       "      <td>606.00</td>\n",
       "      <td>606.00</td>\n",
       "      <td>606.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>78.31</td>\n",
       "      <td>5.41</td>\n",
       "      <td>3.16</td>\n",
       "      <td>1.01</td>\n",
       "      <td>17.70</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.29</td>\n",
       "      <td>2017.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>45.15</td>\n",
       "      <td>1.13</td>\n",
       "      <td>3.79</td>\n",
       "      <td>0.31</td>\n",
       "      <td>28.66</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.00</td>\n",
       "      <td>2.52</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.26</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2015.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>39.25</td>\n",
       "      <td>4.52</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.07</td>\n",
       "      <td>2016.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>78.00</td>\n",
       "      <td>5.37</td>\n",
       "      <td>1.19</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.14</td>\n",
       "      <td>2018.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>119.00</td>\n",
       "      <td>6.21</td>\n",
       "      <td>7.23</td>\n",
       "      <td>1.26</td>\n",
       "      <td>52.80</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.44</td>\n",
       "      <td>2020.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>157.00</td>\n",
       "      <td>7.81</td>\n",
       "      <td>11.65</td>\n",
       "      <td>1.62</td>\n",
       "      <td>76.95</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.94</td>\n",
       "      <td>2021.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       happiness_rank  happiness_score  gdp_per_cap  social_support  \\\n",
       "count          606.00           606.00       606.00          606.00   \n",
       "mean            78.31             5.41         3.16            1.01   \n",
       "std             45.15             1.13         3.79            0.31   \n",
       "min              1.00             2.52         0.00            0.00   \n",
       "25%             39.25             4.52         0.77            0.81   \n",
       "50%             78.00             5.37         1.19            0.95   \n",
       "75%            119.00             6.21         7.23            1.26   \n",
       "max            157.00             7.81        11.65            1.62   \n",
       "\n",
       "       healthy_life_exp  freedom  generosity  corruption_perception    year  \n",
       "count            606.00   606.00      606.00                 606.00  606.00  \n",
       "mean              17.70     0.51        0.15                   0.29 2017.95  \n",
       "std               28.66     0.22        0.16                   0.30    1.97  \n",
       "min                0.00     0.00       -0.26                   0.00 2015.00  \n",
       "25%                0.55     0.36        0.07                   0.07 2016.00  \n",
       "50%                0.76     0.50        0.16                   0.14 2018.00  \n",
       "75%               52.80     0.65        0.25                   0.44 2020.00  \n",
       "max               76.95     0.96        0.82                   0.94 2021.00  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e89ca839",
   "metadata": {},
   "source": [
    "### Is the happiness score in happy countries significantly higher than the happiness score in sad countries?\n",
    "\n",
    "Two Sample T-Test\n",
    "\n",
    "$\\alpha$ = .05\n",
    "\n",
    "$𝐻_{0}$: Happy countries mean happiness score is <= than the mean log error of sad countries.\n",
    "\n",
    "𝐻𝑎: Happy countries mean happiness score is > than the mean log error of sad countries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e239730b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Levene's F-statistic: 0.184\n",
      "P-value: 0.669\n",
      "Fail to reject the null hypothesis.\n"
     ]
    }
   ],
   "source": [
    "#test for equal variance \n",
    "#H0 is that the variances are equal\n",
    "#Ha is that the variances are not equal\n",
    "# if p > .05, variances are not significantly different and set argument to equal_var = True\n",
    "#if p < .05, variances are significantly different and set argument to equal_var = False\n",
    "#Levene test on two groups\n",
    "\n",
    "group_1 = so_sad.happiness_score\n",
    "group_2 = uber_happy.happiness_score\n",
    "\n",
    "#set alpha\n",
    "α = 0.05\n",
    "\n",
    "#perform test to determine variance\n",
    "f, p = stats.levene(so_sad.happiness_score,\n",
    "             uber_happy.happiness_score)\n",
    "\n",
    "#evaluate coefficient and p-value\n",
    "print(f'Levene\\'s F-statistic: {f:.3f}\\nP-value: {p:.3f}')\n",
    "\n",
    "\n",
    "#evaluate if \n",
    "if p < α:\n",
    "    print('Reject the null hypothesis.')\n",
    "else:\n",
    "    print('Fail to reject the null hypothesis.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c9593897",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P Value: 0.000\n",
      "Reject the null hypothesis.\n"
     ]
    }
   ],
   "source": [
    "#set alpha\n",
    "α = 0.05\n",
    "\n",
    "#perform test\n",
    "t, p = stats.ttest_ind(uber_happy.happiness_score, so_sad.happiness_score, equal_var = True)\n",
    "\n",
    "#print p-value\n",
    "print(f'P Value: {p/2:.3f}')\n",
    "\n",
    "#evaluate if mean of the uber_happy countries is significantly higher than so_sad, is p/2 < a and t > 0?\n",
    "if p/2 < α and t > 0:\n",
    "    print('Reject the null hypothesis.')\n",
    "else:\n",
    "    print('Fail to reject the null hypothesis.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5953a3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "822a80d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15be6f0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "babdf6c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f54a32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "57855f84",
   "metadata": {},
   "source": [
    "### \n",
    "\n",
    "One Sample T-Test\n",
    "\n",
    "$\\alpha$ = .05\n",
    "\n",
    "$𝐻_{0}$: Orange County mean log error is <= than the combined mean log errors of Ventura, Los Angeles, and Orange counties.\n",
    "\n",
    "𝐻𝑎: Orange County mean log error is > than the combined mean log errors of Ventura, Los Angeles, and Orange counties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "78e29509",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P Value: 0.000\n",
      "Reject the null hypothesis.\n"
     ]
    }
   ],
   "source": [
    "#set alpha\n",
    "α = 0.05\n",
    "\n",
    "#get sample\n",
    "happy_sample = train[train.uber_happy].happiness_rank\n",
    "\n",
    "#get mean\n",
    "overall_mean = train.happiness_rank.mean()\n",
    "\n",
    "#perform test\n",
    "t, p = stats.ttest_1samp(happy_sample, overall_mean)\n",
    "\n",
    "#print p-value\n",
    "print(f'P Value: {p/2:.3f}')\n",
    "\n",
    "#evaluate if mean of countries that scored well on happiness is significantly lower than all of the countries, is p/2 < a and t < 0?\n",
    "if p/2 < α and t < 0:\n",
    "    print('Reject the null hypothesis.')\n",
    "else:\n",
    "    print('Fail to reject the null hypothesis.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d82f1e80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f8ce997",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f10edbc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f63df30",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
